# Polynomial Regression(다항회귀),다중선형회귀

**비선형 데이터를 학습하기 위해 다차원 식을 만드는 기법**

(보통 대부분 데이터는 선형이지가 않음)

![스크린샷 2023-05-02 오후 3.38.53.png](Polynomial%20Regression(%E1%84%83%E1%85%A1%E1%84%92%E1%85%A1%E1%86%BC%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1),%E1%84%83%E1%85%A1%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%89%E1%85%A5%E1%86%AB%E1%84%92%E1%85%A7%E1%86%BC%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%20cb0dcce029864da4abfa345f9b38d9ea/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-02_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.38.53.png)

이렇게 대부분 비선형 데이터임

노란점 : 데이터

파란 점 : 선형

빨간 곡선 : 다항회귀

데이터 추이에서 선형으로 표현할 수가 없을 때 다항회귀를 사용하게 됨

![스크린샷 2023-05-02 오후 3.39.58.png](Polynomial%20Regression(%E1%84%83%E1%85%A1%E1%84%92%E1%85%A1%E1%86%BC%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1),%E1%84%83%E1%85%A1%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%89%E1%85%A5%E1%86%AB%E1%84%92%E1%85%A7%E1%86%BC%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%20cb0dcce029864da4abfa345f9b38d9ea/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-02_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.39.58.png)

이게 다항회귀 공식이라고 함

<직선으로 어떤 데이터를 충분히 표현하지 못하는 데이터는

데이터의 편향(bias)이 크다고 표현>

다항 회귀에서는 차수가 너무 큰 경우에는 변동성이 커지고, 이를 고분산성을 가진다고 함

>>차수가 높아지면 ?? 복잡성 또한 높아질 것

편향 (bias) 과 분산(Variance)은 한쪽 성능을 좋게 하면, 나머지 하나의 성능이 떨어지는 관계에 있다고 함

이 둘의 성능을 적절하게 맞춰 전체 오류가 낮아지는 지점을 골디락스 지점이라고 정의

차수를 높였을 때의 장점인 모델이 기존의 모델보다 더 적은 오차를 만들어 낸다는 것

어떻게 표현하지 그럼?

머신러닝에서는 결괏값을 구하기 위한 입력 데이터를 feature라고 표현

보통 feature라는 특징을 변형시켜 다항으로 표현을 하는데…

![스크린샷 2023-05-02 오후 3.54.18.png](Polynomial%20Regression(%E1%84%83%E1%85%A1%E1%84%92%E1%85%A1%E1%86%BC%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1),%E1%84%83%E1%85%A1%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%89%E1%85%A5%E1%86%AB%E1%84%92%E1%85%A7%E1%86%BC%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%20cb0dcce029864da4abfa345f9b38d9ea/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-02_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.54.18.png)

이딴 데이터가 있다고 치자 대략 뭐 길이가 길수록 생선들의 무게가 많이 나가는 이런…

![스크린샷 2023-05-02 오후 3.54.43.png](Polynomial%20Regression(%E1%84%83%E1%85%A1%E1%84%92%E1%85%A1%E1%86%BC%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1),%E1%84%83%E1%85%A1%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%89%E1%85%A5%E1%86%AB%E1%84%92%E1%85%A7%E1%86%BC%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%20cb0dcce029864da4abfa345f9b38d9ea/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-02_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.54.43.png)

이렇게 생선의 길이에 차수를 부여, 여러 특징을 만듬

제곱하면 문제 없나?

그냥 뭐 생선의 길이라는 특징을 제곱하여 또 다른 특징을 만들어 낼 수 있게 되는 뭐 그런거

이 AI에서는 특징이 많으면 많을수록 정답을 더 잘맞춘다고 함

그런데 차수가 존나게 많으면 overfitting이 옴

여기서 근데 과대적합을 막으면서 차수를 자동으로 적절히 조절할 수 있는 릿지와 라쏘라는 규제클래스가 있다고 함

규제란?

과대적합을 막으면서 파라미터를 조정

여기서 알아둬야 할 것

다중선형회귀란??

여러개의 특징이 많은 회귀방법인데…

위에서 보면 길이라는 feature가지고만 y를 찾으러 했는데

만약 종류를 맞춰보라고 하면??

그러면 길이하나만으로는 절대 못맞춤

그래서 정답을 맞추기 위해 도움이 될만한 여러가지 생선의 feature를 알려주면 되는데….

독립이란? 서로의 특징에 영향을 주지 않은 요소들!

생선넓이,색깔 뭐 이딴거,,,

다중선형화귀도 다항화귀와 마찬가지로 뭐 특징1개보다는 여러개를 알려주며 target의 특징을 구체화하며 정확도를 높일 수 잇음

![스크린샷 2023-05-02 오후 4.07.39.png](Polynomial%20Regression(%E1%84%83%E1%85%A1%E1%84%92%E1%85%A1%E1%86%BC%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1),%E1%84%83%E1%85%A1%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%89%E1%85%A5%E1%86%AB%E1%84%92%E1%85%A7%E1%86%BC%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%20cb0dcce029864da4abfa345f9b38d9ea/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-02_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.07.39.png)

이 형님의 말 기억

즉

특징이 2개이상인 선형회귀를 다중선형회귀, 1개일때는 선형회귀

![스크린샷 2023-05-02 오후 4.14.01.png](Polynomial%20Regression(%E1%84%83%E1%85%A1%E1%84%92%E1%85%A1%E1%86%BC%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1),%E1%84%83%E1%85%A1%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%89%E1%85%A5%E1%86%AB%E1%84%92%E1%85%A7%E1%86%BC%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%20cb0dcce029864da4abfa345f9b38d9ea/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-02_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.14.01.png)

다중선형회귀의 식