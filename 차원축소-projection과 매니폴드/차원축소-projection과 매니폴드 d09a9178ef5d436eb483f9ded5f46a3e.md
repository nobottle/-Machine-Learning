# 차원축소-projection과 매니폴드

feature은 가끔 훈련을 느리게하고 좋은 솔루션을 찾는데 방해가 되기도 함 이를 cusre of dimensionality(차원의 저주)라고 함

더 자세히 들여다보면,,

많은 머신러닝문제는 훈렴샘플이 존나게 많은 feature를 가지고 있음

이런 많은 feature은 훈련을 느리게 하고 좋은 솔루션을 찾기 어렵게 만들 수 잇음

이러한 차원의 저주  문제들은 feature수를 크게 줄여 불가능한 문제를 가능한 범위로 변경할 수 잇음

예를들어서 뭐…

뭐,,,MNIST이미지처럼, 이미지 경계에 있는 픽셀은, 거의 흰색이므로 이런거는 뭐 훈련세트에서 이러한 픽셀을 제거해도 많은 정보를 잃지 않는다..

또한 인접한 픽셀들은 종종 많은 연관이 있으므로, 두 픽셀을 하나로 합치더라고 잃는 정보다 많지 않음

![스크린샷 2023-05-16 오후 3.00.52.png](%E1%84%8E%E1%85%A1%E1%84%8B%E1%85%AF%E1%86%AB%E1%84%8E%E1%85%AE%E1%86%A8%E1%84%89%E1%85%A9-projection%E1%84%80%E1%85%AA%20%E1%84%86%E1%85%A2%E1%84%82%E1%85%B5%E1%84%91%E1%85%A9%E1%86%AF%E1%84%83%E1%85%B3%20d09a9178ef5d436eb483f9ded5f46a3e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.00.52.png)

자 이러한 차원이 있다고 생각해보자 고차원 공간은 사실 우리가 상상하기 어려움…

예를들어, 2차원에서 두 점을 선택해 이 점이 사각형의 경계선과 가까울 확률보다 100000차원에서 두 점을 선택해서 이 점이 경계선에 가까울 확률이 높다 왜? 여기는 초입방체니까 존나게 많기 때문에, 보면 차원이 늘어날때마다 선들이 경계선들이 늘어나는걸 볼 수 있다.

이런걸 가지고 생각해보면 고차원 데이터셋은 보통 데이터들끼리 멀리 떨어져 가능성이 높다는 걸 유추해 볼 수 있음

즉 이말은 훨씬 더 외삽(extrapolation : 관찰이 어려운 데이터에 대해 추측하는 것)을 요구하기 때문에 불안정해 짐.

즉 이것을 고차원일수록 overfitting위험이 크다고 말함

정리하자면, 고차원일수록 훈련 데이터가 서로 멀리 떨어져 있으며 새로운 샘플도 훈련 샘플과 멀리 떨어져 있을 가능성이 높음

이를 해결하기 위한 이론적인 방법은 고차원에서도 데이터 끼리의 거리가 가까울 수 있도록, 즉 밀도가 높아질 때 까지 dataset의 크기를 키우는 것… 그러나 현실적으로는 흠…?

차원축소를 위한 접근방법에는 두 가지가 있음 투영과 매니폴드 학습

**투영(projection)**

대부분 우리가 마주할 dataset은 모든 차원에 대해 균일하게 퍼져있지 않음… >> 많은 feature들 중 특정 feature들끼리만 강한 연관을 가지는 경우가 많다.

즉, 모든 data들이 고차원 공간 안에서(많은 feature들이 있지만) 저차원 subspace에 놓여 있음

>>특정 feature들끼리 강한 연관을 가지는 경우가 많다

• 따라서 이 **저차원 부분 공간에 수직으로(즉, 샘플과 평면 사이의 가장 짧은 직선을 따라) 투영(projection)**하면, 아래와 같이 **2차원 데이터 셋**을 얻을 수 있다.

![스크린샷 2023-05-16 오후 3.33.06.png](%E1%84%8E%E1%85%A1%E1%84%8B%E1%85%AF%E1%86%AB%E1%84%8E%E1%85%AE%E1%86%A8%E1%84%89%E1%85%A9-projection%E1%84%80%E1%85%AA%20%E1%84%86%E1%85%A2%E1%84%82%E1%85%B5%E1%84%91%E1%85%A9%E1%86%AF%E1%84%83%E1%85%B3%20d09a9178ef5d436eb483f9ded5f46a3e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.33.06.png)

3차원 데이터셋이 있다고 가정하자

보면 data들이 거의 평면 형태로 놓여 있는거를 확일 할 수 있다

이게 3차원 공간에 있는 저차원 subsapce임

여기서 모든 data를 2차원 subspace에 투영하면 $

![스크린샷 2023-05-16 오후 3.37.42.png](%E1%84%8E%E1%85%A1%E1%84%8B%E1%85%AF%E1%86%AB%E1%84%8E%E1%85%AE%E1%86%A8%E1%84%89%E1%85%A9-projection%E1%84%80%E1%85%AA%20%E1%84%86%E1%85%A2%E1%84%82%E1%85%B5%E1%84%91%E1%85%A9%E1%86%AF%E1%84%83%E1%85%B3%20d09a9178ef5d436eb483f9ded5f46a3e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.37.42.png)

다음과 같은 2차원 데이터셋을 얻을 수 있다

이거를 뭐 3차원에서 2차원으로 줄였다고 할 수 있음

이에따라 데이터는 새로운 feature은 z1,z2에 대응됨

그러나…

![스크린샷 2023-05-16 오후 3.48.24.png](%E1%84%8E%E1%85%A1%E1%84%8B%E1%85%AF%E1%86%AB%E1%84%8E%E1%85%AE%E1%86%A8%E1%84%89%E1%85%A9-projection%E1%84%80%E1%85%AA%20%E1%84%86%E1%85%A2%E1%84%82%E1%85%B5%E1%84%91%E1%85%A9%E1%86%AF%E1%84%83%E1%85%B3%20d09a9178ef5d436eb483f9ded5f46a3e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.48.24.png)

이러한 스위스 롤 데이터셋에선 투영이 좋은 방법은 아니다

얘는 부분 공간이 튀틀려 있어서 투영을 통해 차원을 축소시키면 ㅈ같은 결과를 초래한다

![스크린샷 2023-05-16 오후 4.10.45.png](%E1%84%8E%E1%85%A1%E1%84%8B%E1%85%AF%E1%86%AB%E1%84%8E%E1%85%AE%E1%86%A8%E1%84%89%E1%85%A9-projection%E1%84%80%E1%85%AA%20%E1%84%86%E1%85%A2%E1%84%82%E1%85%B5%E1%84%91%E1%85%A9%E1%86%AF%E1%84%83%E1%85%B3%20d09a9178ef5d436eb483f9ded5f46a3e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.10.45.png)

오른쪽처럼 뭉개짐…

**매니폴드 학습**

스위스 롤을 펴게 되면  평면이기 때문에 3차원에서 휘어지고 뒤틀려있는 스위스 롤은 2D매니폴드로 보는 것

응?

스위스 롤은 2D매니폴드의 한 예임

2D 매니폴드는 고차원 공간에서 휘어지거나 뒤틀린 2D모양임

d차원 매니폴드는 국부적으로 d차원초평면으로 보일 수 있는 n차원 공간의 일부

뭔 개소리냐,,,?

예를들어 데이터 공간에 개미 한마리가 산다고 가정할 때 우리는 이 롤을 그래프 밖에서 보기 때문에 점과 점사이 거리를 구할 대 유클리디안 방식으로 구하게 됨, 그러나 개미 입장에선 점프할 수 없기 때문에 롤ㄹ을 따라 바깥으로 도달하여 점과 점 사이의 거리를 구하게 됨

다시 정리하면 d차원 매니폴드는 개미 입장에서 d차원 초평면으로 보일 수 있는 n차원 공간의 일부.. 오호

많은 차원 축소 알고리즘은 이러한 꼬여있는 매니폴드를 풀어헤친 형태를 모델링하는 식으로 작동하는데, 이를 **매니폴드 학습(manifold learning)**이라고 함

매니폴드 학습이 많이 활용되는 가장 큰 이유는 Classification이나 Regression같은 작업 시 저차원 매니폴드 형태로 데이터를 표현하면 훨씬 더 간단해질거라고 가정하기 때문

![스크린샷 2023-05-16 오후 4.44.06.png](%E1%84%8E%E1%85%A1%E1%84%8B%E1%85%AF%E1%86%AB%E1%84%8E%E1%85%AE%E1%86%A8%E1%84%89%E1%85%A9-projection%E1%84%80%E1%85%AA%20%E1%84%86%E1%85%A2%E1%84%82%E1%85%B5%E1%84%91%E1%85%A9%E1%86%AF%E1%84%83%E1%85%B3%20d09a9178ef5d436eb483f9ded5f46a3e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.44.06.png)

근데 이럴 ㅈ같은 경우는 뭐 간단해지지 않음…겹쳐잇음,,

정리 : 매니폴드 학습은 복잡한 데이터 세트를 매니폴드로 모델링하여 복잡한 데이터 세트의 기본 구조를 발견하고 이해하는 것을 목표로 하는 기계 학습의 기술 집합. 목표는 원래 고차원 공간에서 분명하지 않을 수 있는 데이터의 비선형 관계 및 패턴을 캡처하는 것

매니폴드 학습의 주요 목표는 본질적인 특성과 관계를 보존하는 데이터의 저차원 표현을 찾는 것 차원을 줄임으로써 데이터를 보다 쉽게 관리하고 시각화할 수 있슴, 이 저차원 표현은 원래의 고차원 공간에서는 분명하지 않은 클러스터, 패턴 및 유사성을 드러낼 수 있다.