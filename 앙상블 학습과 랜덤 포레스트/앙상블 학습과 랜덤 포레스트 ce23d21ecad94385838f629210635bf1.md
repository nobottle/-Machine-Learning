# 앙상블 학습과 랜덤 포레스트

**soft voting and hard voting**

보통 머신러닝에서도 적당한 성능의 모델 여러개들로부터 예측을 수집하는 것이 하나의 모델 예측보다 좋은 결과를 가져옴

이러한 학습 방법을 앙상블 학습(Ensemble Learning)이라고 함

![스크린샷 2023-05-15 오후 4.06.53.png](%E1%84%8B%E1%85%A1%E1%86%BC%E1%84%89%E1%85%A1%E1%86%BC%E1%84%87%E1%85%B3%E1%86%AF%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%E1%84%80%E1%85%AA%20%E1%84%85%E1%85%A2%E1%86%AB%E1%84%83%E1%85%A5%E1%86%B7%20%E1%84%91%E1%85%A9%E1%84%85%E1%85%A6%E1%84%89%E1%85%B3%E1%84%90%E1%85%B3%20ce23d21ecad94385838f629210635bf1/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-15_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.06.53.png)

보면 logistic regresson, svm, random forest…이러한 정확도가 80%인 다양한 classfier가 있다고 가정하자

![스크린샷 2023-05-15 오후 4.07.50.png](%E1%84%8B%E1%85%A1%E1%86%BC%E1%84%89%E1%85%A1%E1%86%BC%E1%84%87%E1%85%B3%E1%86%AF%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%E1%84%80%E1%85%AA%20%E1%84%85%E1%85%A2%E1%86%AB%E1%84%83%E1%85%A5%E1%86%B7%20%E1%84%91%E1%85%A9%E1%84%85%E1%85%A6%E1%84%89%E1%85%B3%E1%84%90%E1%85%B3%20ce23d21ecad94385838f629210635bf1/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-15_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.07.50.png)

그래서 앙상븍 학습에서는 각 clssifier의 예측을 모아서 가장 많이 선택된 클라스를 예측!

이렇게 다수결 투표로 정해지는 classifier를 직접투표(hard voting)분류기라고 함

여기서 신기한게 다수결 투표의 classifier가 각 앙상블에 포함된 각각classifier들 중 가장 뛰어난 것 보다도 정확도가 높은 경우가 많다

>>각각은 약할지라도 개수가 존나게 많으면 성능이 높을 가능성이 높음

왜? 여기서 나오는 것이 큰수의 법칙데쓰

큰수의 법칙이란? : 독립적인 시행 또는 관찰의 수가 증가함에 따라 이러한 관찰의 평균이 예상 값에 근접하는 경향

ex)주사위를 한 번만 굴리면 결과는 6개의 숫자중 하나이며 평균값은

(1+2+3+4+5+6)/6 = 3.5

근데 10번 굴리면…?

3, 5, 2, 1, 4, 6, 3, 2, 6, 1이라는 일련의 숫자를 얻었다고 가정하면, 평균값은 (3+5+2+1+4+6+ 3+2+6+1)/10 = 3.3

100번 굴리면 예상값인 3.5에 더 가깝, 1000번 굴리면 훨씬 더 가까워짐10,000 또는 백만과 같이 매우 큰 숫자로 늘리면 평균값이 3.5에 훨씬 더 가깝게 수렴… 뭐 이딴거라고 함

정리하자면 hard voting : 앙상블의 각 모델이 단일 투표를 하고 다수의 예측이 최종 예측으로 선택됨, 가장 많은 표를 얻은 클래스가 이김

ex)

주어진 이메일이 스팸인지 여부를 예측하려는 분류 작업이 있다고 가정 Decision Tree, Logistic Regression 및 SVM(Support Vector Machine)의 세 가지 개별 분류기로 구성된 앙상블이 있다고 할 경우

의사 결정 트리는 이메일이 스팸이라고 예측하고, 로지스틱 회귀 분석은 스팸이 아니라고 예측하고, SVM은 스팸이라고 예측, 강성 투표에서 각 모델의 예측은 단일 투표로 처리됨

앙상블에 세 가지 모델이 있으므로 다수결을 고려. 이 경우 두 모델(의사결정 트리 및 SVM)은 스팸을 예측한 반면, 하나의 모델(로지스틱 회귀)은 스팸이 아닌 것으로 예측했으므로 따라서 대다수는 이메일을 스팸으로 분류하는 데 찬성할 것

결과적으로 하드 투표에 기반한 앙상블의 최종 예측은 이메일이 개별 모델로부터 가장 많은 표를 받았기 때문에 스팸이라는 것

뭐 이딴거…

그리고 앙상블 내 모든 clssifier가 클래스의 확률을 예측할 수 있다면, classifier의 예측을 평균 내어 확률이 가장 높은 클래스를 예측할 수 있는데, 이를 간접투표(soft voting)이라고 함

이게 hard voting보다 성능이 높음

soft voting :

꽃잎 길이와 너비를 기반으로 꽃의 종을 예측하는 분류 작업이 있다고 가정 Random Forest, KNN(K-Nearest Neighbors) 및 Naive Bayes의 세 가지 개별 분류기로 구성된 앙상블이 있을 때

Random Forest는 확률을 A종 60%, B종 35%, C종 5%로 예측

KNN은 A종 20%, B종 70%, C종 10%로 예측. Naive Bayes는 종 A에 대해 50%, 종 B에 대해 25%, 종 C에 대해 25%를 예측

소프트 보팅에서는 각 모델이 할당한 확률을 결합하여 최종 예측을 함

일반적인 접근 방식 중 하나는 각 클래스의 평균 확률을 계산하는 것입니다.

종 A에 대한 평균 확률을 계산하기 위해 (60% + 20% + 50%)/3 = 43.33%를 취함 종 B의 경우 (35% + 70% + 25%)/3 = 43.33%그리고 종 C의 경우 (5% + 10% + 25%)/3 = 13.33%

이러한 평균 확률을 기반으로 확률이 가장 높은 클래스가 최종 예측으로 선택되는데 이 경우 종 A와 종 B 모두 평균 확률이 43.33%로 종 C의 평균 확률 13.33%보다 높다

따라서 소프트 투표를 기반으로 한 앙상블의 최종 예측은 사용된 동률 결정 전략(예: 동률인 경우 첫 번째 클래스 선택)에 따라 종 A 또는 종 B가 됨

****Bagging과 Pasting****

다양한 classifier를 만드는 방법은 training알고리즘을 사용하는 것,

다른 하나는 같은 알고리즘을 사용하되, training dataset의 subset을 무작위로 구성하여 classifier마다 다른 데이터로 학습 시키는 것

![스크린샷 2023-05-15 오후 4.59.58.png](%E1%84%8B%E1%85%A1%E1%86%BC%E1%84%89%E1%85%A1%E1%86%BC%E1%84%87%E1%85%B3%E1%86%AF%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%E1%84%80%E1%85%AA%20%E1%84%85%E1%85%A2%E1%86%AB%E1%84%83%E1%85%A5%E1%86%B7%20%E1%84%91%E1%85%A9%E1%84%85%E1%85%A6%E1%84%89%E1%85%B3%E1%84%90%E1%85%B3%20ce23d21ecad94385838f629210635bf1/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-15_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.59.58.png)

이때 training dataset에서 중복을 허용하여 subset을 나눠 학습하는 것을 배깅(Bagging), 중복을 허용하지 않는 것을 페이스팅(pasting)이라고 함

다시 말하면, 하나의 training data가 하나의 classifier를 위해 여러 번 학습에 사용될 수 있는 건 Bagging뿐

모든 분류기가 학습을 마치면,앙상블은 이들의 예측을 모두 모아 새로운 Data에 대한 예측을 만듬

이때 최종 예측을 하는 수집함수는 Classification일 땐, Hard Voting Classifier처럼 가장 많은 예측 결과를 따르고, Regression에 대해선 평균을 계산함

**oob평가**

Bagging을 사용하면 어떤 데이터는 여러번 사용, 어떤 것은 전혀 선택되지 않을 수도 잇음

이 때 사용되지 않은 data을 oob(out of bag)이라고 함

뭐 근데 이 oob도 따로 예측 평가하는데 사용하기도 함, validation set처럼 말이다

****랜덤 패치와 랜덤 서브스페이스****

baggingclassifier에서 각 예측기를 학습하는데 일부 데이터만 쓰는 기능도 있지만, 일부 feature만 반영시키는 기능도 함…

무슨 말이야?

>>예를들어 데이터가 10개의 feature를 가지고 있는데, 5개의 feature만 학습에 사용하는 방식

더 쉽게 예를들면,

구독 서비스에 대한 고객 정보 데이터 세트가 있다고 할 때 기능에는 연령, 성별, 소득, 사용 패턴, 고객 만족도 등급 등이 포함될 수 있다, 각 기능은 고객에 대한 특정 정보를 제공하며 기계 학습 모델에서 예측을 수행하는 데 사용 이런 게 다 feature라고 보면 됨

이딴 방식들은 고차원의 데이터셋을 다룰 때 유용하다고 함.

feature와 데이터를 모두 일부만 사용하는 것을 랜덤 패치 방식(Random pathes Method)라고 함

그리고 데이터는 모두 사용, feature만 일부 사용하는 방식을 랜덤 서브스페이스 방식(Random subspace method)라고 함

 랜덤 패치 방식(Random pathes Method) : 데이터 : 일부, feature : 일부

랜덤 서브스페이스 방식(Random subspace method) : 데이터 : 모두 feature : 일부

**Random foreset**

랜덤 포레스트는 Bagging or pasting을 적용한 decision tree의 앙상블임!

좀 예를들어서 정리 :

이메일이 스팸인지 여부를 예측하는 예를 사용하여 Random Forest 알고리즘을 살펴보자면

이메일로 구성된 데이터 세트가 있고 각 이메일이 특정 단어의 존재, 이메일 길이, 느낌표 수 등과 같은 다양한 기능이 있을 때  대상 변수는 이메일이 스팸(1)인지 또는 스팸이 아닌지(0)로 분류되는지 여부를 나타냄

다음은 Random Forest 모델 구축과 관련된 주요 단계

1. 데이터 세트 준비:
    - 데이터 세트를 훈련 세트와 테스트 세트의 두 부분으로 나눔 훈련 세트는 Random Forest 모델을 훈련하는 데 사용되고 테스트 세트는 성능을 평가하는 데 사용
2. 랜덤 포레스트 건설:
    - Random Forest 알고리즘은 결정 트리의 앙상블로 구성, 각 의사 결정 트리는 학습 데이터의 서로 다른 하위 집합에서 학습
    - 의사 결정 트리를 구축하는 각 단계에서 교육 데이터의 임의 하위 집합이 교체로 샘플링(부트스트래핑이라고 함). 이는 일부 샘플이 하위 집합에서 반복될 수 있는 반면 다른 샘플은 생략될 수 있음을 의미
    - 또한 각 의사 결정 트리를 구성할 때 각 분할에 대해 임의의 기능 하위 집합만 고려됩니다. 이를 기능 서브샘플링이라고 함 예를 들어 10개의 기능이 있는 경우 주어진 의사 결정 트리의 각 분할에 대해 5개의 기능 하위 집합을 무작위로 선택할 수 있음
    - 부트스트래핑 및 기능 서브샘플링을 통해 임의성을 도입함으로써 Random Forest는 다양한 결정 트리를 생성하여 과적합 가능성을 줄이고 모델의 견고성을 높임
3. 교육 단계:
    - Random Forest의 각 결정 트리는 교육 데이터 및 기능의 하위 집합을 사용하여 성장
    - 트리는 선택한 기능을 기반으로 데이터를 재귀적으로 분할하여 특정 기준(예: 지니 불순도 또는 정보 획득)을 최적화하여 구축
    - leaf 노드에 필요한 최대 깊이 또는 최소 샘플 수에 도달하는 것과 같은 중지 기준이 충족될 때까지 트리가 성장
    - 학습 과정은 Random Forest의 모든 결정 트리가 구성될 때까지 계속
4. 예측 단계:
    - 예측을 위해 Random Forest는 앙상블의 모든 결정 트리에서 예측을 결합. 스팸 탐지와 같은 분류 작업의 경우 가장 일반적인 접근 방식은 투표
    - 예를 들어 Random Forest에 100개의 결정 트리가 있는 경우 각 트리는 주어진 이메일에 대해 예측을 함 최종 예측은 모든 결정 트리의 다수결이 될 것 가장 많은 표를 얻은 클래스(스팸 여부)가 최종 예측으로 선택
5. 평가:
    - Random Forest 모델의 성능은 테스트 세트를 사용하여 평가. 앙상블이 만든 예측은 정확도, 정밀도, 재현율 또는 F1 점수와 같은 메트릭을 측정하기 위해 테스트 세트의 실제 레이블과 비교됩니다.
    - 본 적이 없는 데이터에 대한 모델의 성능을 평가하여 본 적이 없는 새로운 이메일을 일반화하고 정확하게 예측하는 능력을 측정할 수 있음

![스크린샷 2023-05-15 오후 8.04.05.png](%E1%84%8B%E1%85%A1%E1%86%BC%E1%84%89%E1%85%A1%E1%86%BC%E1%84%87%E1%85%B3%E1%86%AF%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%E1%84%80%E1%85%AA%20%E1%84%85%E1%85%A2%E1%86%AB%E1%84%83%E1%85%A5%E1%86%B7%20%E1%84%91%E1%85%A9%E1%84%85%E1%85%A6%E1%84%89%E1%85%B3%E1%84%90%E1%85%B3%20ce23d21ecad94385838f629210635bf1/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-15_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_8.04.05.png)

그림으로 따지면 이러한 형태

**엑스트라 트리**

랜덤 포레스트는 각 노드의 분할을 위해 feature의 subset을 사용함, 트리를 더욱 무작위하게 만들기 위해 feature의 subset을 사용하 무작위로 분할 후 그중 최상의 분할을 선택

이렇게 극단적으로 무작위한 랜덤 포레스트를 extreme random tree앙상블 Or 엑스트라 트리 라고 함

>>무작위성을 존나게 늘려 다양성이 늘어남 이는 곧 편향을 늘리는 대신 분산을 줄이게 됨

기존엔 노드 분할 시 최적의 임곗값을 찾는 것이 트리 알고리즘에서 가장 많이 시간을 잡아먹는 부분이었는데 이것이 없어졌으므로 일반적인 Random Forest보다 Extra Tree가 훨씬 빠르다고 함

****Random Forest vs Extra Trees****

랜덤 포레스트와 엑스트라 트리의 차이점은 부트스트랩 샘플(중복된 훈련 샘플)을 사용하지 않는다는 점

엑스트라 트리는 결정 트리를 만들어 낼 때 훈련 세트 전체를 사용하기 때문에 Bagging이라고는 할 수 없음

또 랜덤포레스트는 주어진 모든 feature에 대한 정보이득을 계산하고 가장 높은 정보 이득을 가지는 feature를 Split Node로 선택, 그것들은 전부 비교해서 가장 최선의 feature를 선정. 이 과정을 통해 성능이 좋은 결정트리를 만들 수 있지만 연산량이 많이 든다는 단점이 있음

반면에 엑스트라 트리는 Split을 할 때 무작위로 feature를 선정, feature중에 아무거나 고른 다음 그 feature에 대해서 최적의 Node를 분할. 성능이 낮아지지만 생각보다 준수한 성능을 보이고 과대적합을 막고 검증 세트의 점수를 높이는 효과가 있음. 그리고 속도가 빠르다는 장점이 있다

**특성 중요도**

랜덤 포레스트의 장점은 어떤 feature가 예측에 중요한 비중을 차지하는지 상대적인 중요도를 측정하기 쉽다는 것

**Boosting**

부스팅(Boosting)은 약한 학습기를 여러 개 연결하여 강한 학습기를 만드는 앙상블 방법 여기에는 AdaBoost와 Gradient Boosting가 있음

AdaBoost

이전 모델이 underfitting했던 training data의 가중치를 더 높이며 새로운 모델을 만듬

이렇게 새로운 예측기는 학습하기 어려운 샘플에 점점 더 맞춰진다고 함

![스크린샷 2023-05-15 오후 8.24.28.png](%E1%84%8B%E1%85%A1%E1%86%BC%E1%84%89%E1%85%A1%E1%86%BC%E1%84%87%E1%85%B3%E1%86%AF%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%E1%84%80%E1%85%AA%20%E1%84%85%E1%85%A2%E1%86%AB%E1%84%83%E1%85%A5%E1%86%B7%20%E1%84%91%E1%85%A9%E1%84%85%E1%85%A6%E1%84%89%E1%85%B3%E1%84%90%E1%85%B3%20ce23d21ecad94385838f629210635bf1/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-15_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_8.24.28.png)

위 그림처럼 adaboost분류기를 만들 때 먼저 decision tree와 같은 첫번째 분류기를 training set에 훈련시키고 예측, 그 다음 알고리즘이 잘못 분류했떤 training data의 가중치를 높임

이것이 반영된 두번째 분류기에서는 업데이트된 가중치로 training set을 학습하고 예측,

이게 계속 반복되는 식

식은…

![스크린샷 2023-05-15 오후 8.33.04.png](%E1%84%8B%E1%85%A1%E1%86%BC%E1%84%89%E1%85%A1%E1%86%BC%E1%84%87%E1%85%B3%E1%86%AF%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%E1%84%80%E1%85%AA%20%E1%84%85%E1%85%A2%E1%86%AB%E1%84%83%E1%85%A5%E1%86%B7%20%E1%84%91%E1%85%A9%E1%84%85%E1%85%A6%E1%84%89%E1%85%B3%E1%84%90%E1%85%B3%20ce23d21ecad94385838f629210635bf1/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-15_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_8.33.04.png)

Boosting : 약한 모형을 이용하여 강력한 모형을 만들어 내는 것이 특징인 알고리즘

AdaBoost는 이러한 비정상적 데이터에 빠르게 적응하여 예측력이 강한 모델을 실시간으로 학습

AdaBoost는 매 스텝마다 이전 학습데이터에서 오차가 크거나 오분류된 데이터의 가중치를 크게 함,

오차가 작거나 정분류된 데이터의 가중치를 낮게 함

정리하자면 Adaboost는 약한 모형으로부터 시작하여 이전 모형의 약점을 보완한 새로운 모형들으 ㅣ선형결합을 통해 강한 모형을 얻는 알고리즘 데쓰